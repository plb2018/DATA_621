---
title: "R Notebook"
output: html_notebook
---


```{r}
rm(list = ls(all.names = TRUE)) 
library(knitr)
library(caret)
library(pROC)

```
# Question 1

The data has been downloaded and moved to github in the interest of reproducibility.

# Question 2

```{r}
rm(list = ls(all.names = TRUE)) 

inputDataPath <- "https://raw.githubusercontent.com/plb2018/DATA_621/master/HW2/classification-output-data.csv"

data <- read.csv(inputDataPath)
```

```{r}
cm <- table(data$scored.class,data$class)
colnames(cm)<-c("Actual Negative","Actual Positive")
rownames(cm)<-c("Predicted Negative","Predicted Positive")
kable(cm)

```

Here we create a helper function that computes TP, TN, FP and FN, which are inputs for questions 3-8

```{r}

probs <- function(inputData) {
  cm <- as.list(table(inputData[,2],inputData[,1]))
  names(cm) <- c("TN","FP","FN","TP")
  return(cm)
  }



p<-probs(data[,9:10])
p

#kable(t(p))
#meow$TP <- meow[,1] == 1 & meow[,2] == 1

```

# Questions 3-8

```{r}

accuracy <- function(data) {
  p <- probs(data[,9:10])
  result <- (p$TP + p$TN)/(p$TP + p$FP + p$TN + p$FN)
  return(result)
}


error.rate <- function(data) {
    p <- probs(data[,9:10])
    result <- (p$FP + p$FN)/(p$TP + p$FP + p$TN + p$FN)
  return(result)
}


precision <- function(data) {
    p <- probs(data[,9:10])
    result <- (p$TP )/(p$TP + p$FP)
  return(result)
}

sens <- function(data) {
    p <- probs(data[,9:10])
    print(paste0("probs:", p))
    print(paste0("TP:", p$TP))
    print(paste0("FN:", p$FN))
    print(paste0("result:", p$TP/(p$TP +p$FN)))
    result <- p$TP/(p$TP +p$FN)
  return(result)
}

spec<- function(data) {
    p <- probs(data[,9:10])
    result <- (p$TN)/(p$FP + p$TN)
  return(result)
}

f1.score <- function(data) {
    p <- probs(data[,9:10])
    result <- 2* precision(data) * sens(data) /( precision(data) + sens(data))
  return(result)
}

all_metrics <- function(data){
    
  metrics <- list(accuracy=accuracy(data),
              error.rate=error.rate(data),
              precision=precision(data),
              sensitivity=sens(data),
              specificity=spec(data),
              f1.score=f1.score(data))

  metrics <- lapply(metrics,round,4)
  
  return(t(metrics)) 
} 

sens(data)
spec(data)

```


# Question 9

I find this particular question easier to think about if we rearrange the F1 Score formula like so:


$$
f1 = \frac{2*sensitivity*precision}{sensitivity+precision} = \frac{2}{(sensitivity^{-1} + precision^{-1})}
$$

Because we know that sensitivity and precision are both bounded by 1 and zero, we can see that the minimum value for each term in the denominator is 1 i.e.: $1^{-1} = 1$ the minimum value for the denominator is 2.  Given that the min value for the denominator is 2, the maximum output for the f1 score is $\frac{2}{1+1}=1$.  As sensitivity and precision get small, the denominator increases and the output of the f1 equation approaches zero.


# Question 10

THIS NEEDS WORK STILL!!!

```{r}

myROC <- function(x,y){
  x <- x[order(y, decreasing=TRUE)]
  TP = cumsum(x)/sum(x)
  FP = cumsum(!x)/sum(!x)
  
  df <- data.frame(TP, FP)
  diffFP <- c(diff(FP), 0)
  diffTP <- c(diff(TP), 0)
  auc <- sum(TP * diffFP) + sum(diffTP * diffFP)/2
  
  plot(df$TP)
  
  return(c(df=df, auc = auc))
}

r <- myROC(data$class, data$scored.probability)


```

# Question 11

```{r}
m <-  all_metrics(data)
kable(m)
```

# Question 12

```{r}

predicted <- as.factor(data$scored.class)
actual <- as.factor(data$class)

confusionMatrix(data = predicted , reference = actual ,positive="1")

sensitivity(data = predicted, reference = actual, positive = "1", negative = "0")
specificity(data = predicted, reference = actual, positive = "1", negative = "0")


```

# Question 13


 
```{r}

roc(data$class,data$scored.probability,plot=T)

```



```{r}

inputs = data[,9:10]

accuracy(data)

error.rate(data)

accuracy(data)+error.rate(data)

precision(data)
sensitivity(data)


```
